{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"generate_with_cutting_option.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"wbhs2bXiDIG1","colab_type":"code","outputId":"26b25bba-b9c7-488a-931d-30690d35b027","executionInfo":{"status":"ok","timestamp":1550937096820,"user_tz":-120,"elapsed":25292,"user":{"displayName":"Shlomo Spitzer","photoUrl":"","userId":"03460073492546677144"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","work_DIR = \"/content/drive/My Drive/Deep Learning Course/project_301558086_305143315/YOLO3_Barcode_Detection/qqwweee2\"\n","\n","weights_for_generation = \"/logs/002_1class/trained_weights_final.h5\"\n","\n","cut_the_predictions = True\n","cropped_pictures_folder = \"/cropped_images/\"\n","detection_folder = \"/detections/\"\n","save_detection = True\n","save_cropped = False\n","one_by_one_detection = True\n","\n","from os import chdir\n","chdir(work_DIR)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"id":"GcmokX57G--V","colab_type":"code","outputId":"c5e294bb-89ae-4545-c27f-f7886fdf9997","executionInfo":{"status":"ok","timestamp":1550937100185,"user_tz":-120,"elapsed":28644,"user":{"displayName":"Shlomo Spitzer","photoUrl":"","userId":"03460073492546677144"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Class definition of YOLO_v3 style detection model on image and video\n","\"\"\"\n","\n","import colorsys\n","import os\n","from timeit import default_timer as timer\n","\n","import numpy as np\n","from keras import backend as K\n","from keras.models import load_model\n","from keras.layers import Input\n","from PIL import Image, ImageFont, ImageDraw\n","\n","from yolo3.model import yolo_eval, yolo_body, tiny_yolo_body\n","from yolo3.utils import letterbox_image\n","import os\n","from keras.utils import multi_gpu_model\n","\n","class YOLO(object):\n","    _defaults = {\n","        \"model_path\": work_DIR+weights_for_generation, #'model_data/yolo.h5',\n","        \"anchors_path\": 'model_data/yolo_anchors.txt',\n","        \"classes_path\": 'model_data/1D_classes.txt',\n","        \"score\" : 0.3,\n","        \"iou\" : 0.45,\n","        \"model_image_size\" : (480, 640),\n","        \"gpu_num\" : 1,\n","    }\n","\n","    @classmethod\n","    def get_defaults(cls, n):\n","        if n in cls._defaults:\n","            return cls._defaults[n]\n","        else:\n","            return \"Unrecognized attribute name '\" + n + \"'\"\n","\n","    def __init__(self, **kwargs):\n","        self.__dict__.update(self._defaults) # set up default values\n","        self.__dict__.update(kwargs) # and update with user overrides\n","        self.class_names = self._get_class()\n","        self.anchors = self._get_anchors()\n","        self.sess = K.get_session()\n","        self.boxes, self.scores, self.classes = self.generate()\n","\n","    def _get_class(self):\n","        classes_path = os.path.expanduser(self.classes_path)\n","        with open(classes_path) as f:\n","            class_names = f.readlines()\n","        class_names = [c.strip() for c in class_names]\n","        return class_names\n","\n","    def _get_anchors(self):\n","        anchors_path = os.path.expanduser(self.anchors_path)\n","        with open(anchors_path) as f:\n","            anchors = f.readline()\n","        anchors = [float(x) for x in anchors.split(',')]\n","        return np.array(anchors).reshape(-1, 2)\n","\n","    def generate(self):\n","        model_path = os.path.expanduser(self.model_path)\n","        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n","\n","        # Load model, or construct model and load weights.\n","        num_anchors = len(self.anchors)\n","        num_classes = len(self.class_names)\n","        is_tiny_version = num_anchors==6 # default setting\n","        try:\n","            self.yolo_model = load_model(model_path, compile=False)\n","        except:\n","            self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\n","                if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\n","            self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\n","        else:\n","            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n","                num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\n","                'Mismatch between model and given anchor and class sizes'\n","\n","        print('{} model, anchors, and classes loaded.'.format(model_path))\n","\n","        # Generate colors for drawing bounding boxes.\n","        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n","                      for x in range(len(self.class_names))]\n","        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n","        self.colors = list(\n","            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n","                self.colors))\n","        np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n","        np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n","        np.random.seed(None)  # Reset seed to default.\n","\n","        # Generate output tensor targets for filtered bounding boxes.\n","        self.input_image_shape = K.placeholder(shape=(2, ))\n","        if self.gpu_num>=2:\n","            self.yolo_model = multi_gpu_model(self.yolo_model, gpus=self.gpu_num)\n","        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n","                len(self.class_names), self.input_image_shape,\n","                score_threshold=self.score, iou_threshold=self.iou)\n","        return boxes, scores, classes\n","      \n","    def crop_predictions(self, image, top, left, bottom, right, pic_name):\n","       \n","        pixels = np.array(image)\n","        hi = pixels.shape[0]\n","        wi = pixels.shape[1]\n","        if top < 0:\n","          top = 0\n","        if bottom > hi:\n","          botom = hi-1\n","        if left < 0:\n","          left = 0\n","        if right > wi:\n","          right = wi\n","        new_img = pixels[top:bottom,left:right]\n","        \n","        cropped_image = Image.fromarray(new_img)\n","        if True: #try\n","            \n","            #print(work_DIR+cropped_pictures_folder+pic_name)\n","            if save_cropped:\n","              cropped_image.save(work_DIR+cropped_pictures_folder+pic_name)\n","            plt.figure()\n","            plt.imshow(cropped_image) \n","            plt.show()\n","            cropped_image.show()\n","            print(\"cropped part saved at \"+work_DIR+cropped_pictures_folder+pic_name)\n","        else: #xcept:\n","            print(\"didn't save\")\n","        return cropped_image\n","      \n","    def detect_image(self, image, name='test.png'):\n","        start = timer()\n","\n","        if self.model_image_size != (None, None):\n","            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n","            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n","            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size))) #pad it\n","        else:\n","            new_image_size = (image.width - (image.width % 32),\n","                              image.height - (image.height % 32))\n","            boxed_image = letterbox_image(image, new_image_size)\n","        image_data = np.array(boxed_image, dtype='float32')\n","\n","        print(image_data.shape)\n","        image_data /= 255.\n","        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n","\n","        out_boxes, out_scores, out_classes = self.sess.run(\n","            [self.boxes, self.scores, self.classes],\n","            feed_dict={\n","                self.yolo_model.input: image_data,\n","                self.input_image_shape: [image.size[1], image.size[0]],\n","                K.learning_phase(): 0\n","            })\n","\n","        print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n","\n","        font = ImageFont.truetype(font='font/FiraMono-Medium.otf',\n","                    size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n","        thickness = (image.size[0] + image.size[1]) // 300\n","\n","        for i, c in reversed(list(enumerate(out_classes))):\n","            predicted_class = self.class_names[c]\n","            box = out_boxes[i]\n","            score = out_scores[i]\n","\n","            label = '{} {:.2f}'.format(predicted_class, score)\n","            draw = ImageDraw.Draw(image)\n","            label_size = draw.textsize(label, font)\n","\n","            top, left, bottom, right = box\n","            top = max(0, np.floor(top + 0.5).astype('int32'))\n","            left = max(0, np.floor(left + 0.5).astype('int32'))\n","            bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n","            right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n","            print(label, (left, top), (right, bottom))\n","            print('cropped detections:')\n","            self.crop_predictions(image, top, left, bottom, right, name).show()\n","            \n","            if top - label_size[1] >= 0:\n","                text_origin = np.array([left, top - label_size[1]])\n","            else:\n","                text_origin = np.array([left, top + 1])\n","\n","            # My kingdom for a good redistributable image drawing library.\n","            for i in range(thickness):\n","                draw.rectangle(\n","                    [left + i, top + i, right - i, bottom - i],\n","                    outline=self.colors[c])\n","            draw.rectangle(\n","                [tuple(text_origin), tuple(text_origin + label_size)],\n","                fill=self.colors[c])\n","            draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n","            del draw\n","\n","        end = timer()\n","        print(\"detection time:\")\n","        print(end - start)\n","        \n","        return image\n","\n","    def close_session(self):\n","        self.sess.close()\n","\n","def detect_video(yolo, video_path, output_path=\"\"):\n","    import cv2\n","    vid = cv2.VideoCapture(video_path)\n","    if not vid.isOpened():\n","        raise IOError(\"Couldn't open webcam or video\")\n","    video_FourCC    = int(vid.get(cv2.CAP_PROP_FOURCC))\n","    video_fps       = vid.get(cv2.CAP_PROP_FPS)\n","    video_size      = (int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)),\n","                        int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n","    isOutput = True if output_path != \"\" else False\n","    if isOutput:\n","        print(\"!!! TYPE:\", type(output_path), type(video_FourCC), type(video_fps), type(video_size))\n","        out = cv2.VideoWriter(output_path, video_FourCC, video_fps, video_size)\n","    accum_time = 0\n","    curr_fps = 0\n","    fps = \"FPS: ??\"\n","    prev_time = timer()\n","    while True:\n","        return_value, frame = vid.read()\n","        image = Image.fromarray(frame)\n","        image = yolo.detect_image(image)\n","        result = np.asarray(image)\n","        curr_time = timer()\n","        exec_time = curr_time - prev_time\n","        prev_time = curr_time\n","        accum_time = accum_time + exec_time\n","        curr_fps = curr_fps + 1\n","        if accum_time > 1:\n","            accum_time = accum_time - 1\n","            fps = \"FPS: \" + str(curr_fps)\n","            curr_fps = 0\n","        cv2.putText(result, text=fps, org=(3, 15), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n","                    fontScale=0.50, color=(255, 0, 0), thickness=2)\n","        cv2.namedWindow(\"result\", cv2.WINDOW_NORMAL)\n","        cv2.imshow(\"result\", result)\n","        if isOutput:\n","            out.write(result)\n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            break\n","    yolo.close_session()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"ww4G-XFSD2FU","colab_type":"code","outputId":"4d6ed2ed-6eb9-4f96-86a7-53d877d61c53","executionInfo":{"status":"error","timestamp":1550940036658,"user_tz":-120,"elapsed":115634,"user":{"displayName":"Shlomo Spitzer","photoUrl":"","userId":"03460073492546677144"}},"colab":{"base_uri":"https://localhost:8080/","height":1173}},"cell_type":"code","source":["import sys\n","import argparse\n","#from yolo import YOLO, detect_video\n","from PIL import Image\n","pic_dir = \"/content/drive/My Drive/Deep Learning Course/project_301558086_305143315/YOLO3_Barcode_Detection/qqwweee2/pictures/\"\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","\n","def detect_img(yolo):\n","    while True:\n","        img = input('Input image filename, example - 123.png from the picture folder: ')  # for example :  05102009135.png 05102009124.jpg 05102009115.jpg\n","        try:\n","            image = Image.open(pic_dir+img)\n","        except:\n","            print('Open Error! Try again!') \n","            continue\n","        else:\n","            r_image = yolo.detect_image(image)\n","            r_image.show()\n","            plt.figure()\n","            plt.imshow(r_image) \n","            plt.show()  # display it\n","    yolo.close_session()\n","    \n","def detect_all_img(yolo):\n","    with open(work_DIR+'/train.txt', 'r') as the_file:\n","      lines = the_file.readlines()\n","  \n","      pics_num = len(lines)\n","      for pic in range(pics_num):\n","    \n","        line = lines[pic].split(\" \")\n","        name = line[0].replace('/pictures/','cropped')\n","        #name = name.replace('jpg','png')\n","\n","        try:\n","          image = Image.open(work_DIR+line[0])\n","        except:\n","          try:\n","            image = Image.open((work_DIR+line[0]).replace(\"png\", \"jpg\"))\n","          except:\n","            try:\n","              image = Image.open((work_DIR+line[0]).replace(\"jpg\", \"png\"))\n","            except:\n","              print(\"can't open image\")\n","              raise Exception(\"can't open image\")\n","\n","        r_image = yolo.detect_image(image,name)\n","        if save_detection:\n","          r_image.save(work_DIR+detection_folder+name)\n","          \n","        plt.figure()\n","        plt.imshow(r_image) \n","        plt.show()  # display it\n","        \n","    yolo.close_session()\n","Y = YOLO()\n","if one_by_one_detection:\n","  detect_img(Y)\n","else:\n","  detect_all_img(Y)\n","  \n","print('done')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","/content/drive/My Drive/Deep Learning Course/project_301558086_305143315/YOLO3_Barcode_Detection/qqwweee2/logs/002_1class/trained_weights_final.h5 model, anchors, and classes loaded.\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-8ed06a612351>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mdetect_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;31m#detect_all_img(Y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-8ed06a612351>\u001b[0m in \u001b[0;36mdetect_img\u001b[0;34m(yolo)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdetect_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myolo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input image filename, example - 123.png from the picture folder: '\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# for example : PICT0036 05102009135.png 05102009124.jpg 05102009115.jpg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}